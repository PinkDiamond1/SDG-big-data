<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 3 Finetuning BERT-based models | Twitter Analytics</title>
  <meta name="description" content="Guided step by step analysis of the labor market using NLP on Twitter data." />
  <meta name="generator" content="bookdown 0.23 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 3 Finetuning BERT-based models | Twitter Analytics" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Guided step by step analysis of the labor market using NLP on Twitter data." />
  <meta name="github-repo" content="rstudio/bookdown-demo" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 3 Finetuning BERT-based models | Twitter Analytics" />
  
  <meta name="twitter:description" content="Guided step by step analysis of the labor market using NLP on Twitter data." />
  

<meta name="author" content="Chapter 3 Finetuning BERT-based models | Twitter Analytics Group" />


<meta name="date" content="2021-08-26" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="training-data-preparation.html"/>
<link rel="next" href="labor-market-analysis-with-twitter-data-1.html"/>
<script src="libs/header-attrs-2.10/header-attrs.js"></script>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">GPS Mobility Analysis</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Labor market analysis with Twitter data</a></li>
<li class="chapter" data-level="2" data-path="training-data-preparation.html"><a href="training-data-preparation.html"><i class="fa fa-check"></i><b>2</b> Training data preparation</a>
<ul>
<li class="chapter" data-level="2.1" data-path="training-data-preparation.html"><a href="training-data-preparation.html#sampling"><i class="fa fa-check"></i><b>2.1</b> Sampling</a></li>
<li class="chapter" data-level="2.2" data-path="training-data-preparation.html"><a href="training-data-preparation.html#labelling"><i class="fa fa-check"></i><b>2.2</b> Labelling</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="training-data-preparation.html"><a href="training-data-preparation.html#creating-a-qualtrics-survey"><i class="fa fa-check"></i><b>2.2.1</b> Creating a Qualtrics survey</a></li>
<li class="chapter" data-level="2.2.2" data-path="training-data-preparation.html"><a href="training-data-preparation.html#sharing-the-survey-on-mturk"><i class="fa fa-check"></i><b>2.2.2</b> Sharing the survey on MTurk</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="finetuning-bert-based-models.html"><a href="finetuning-bert-based-models.html"><i class="fa fa-check"></i><b>3</b> Finetuning BERT-based models</a>
<ul>
<li class="chapter" data-level="3.1" data-path="finetuning-bert-based-models.html"><a href="finetuning-bert-based-models.html#training-the-model"><i class="fa fa-check"></i><b>3.1</b> Training the model</a></li>
<li class="chapter" data-level="3.2" data-path="finetuning-bert-based-models.html"><a href="finetuning-bert-based-models.html#evaluation-on-the-random-set"><i class="fa fa-check"></i><b>3.2</b> Evaluation on the random set</a></li>
<li class="chapter" data-level="3.3" data-path="finetuning-bert-based-models.html"><a href="finetuning-bert-based-models.html#active-learning"><i class="fa fa-check"></i><b>3.3</b> Active learning</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="labor-market-analysis-with-twitter-data-1.html"><a href="labor-market-analysis-with-twitter-data-1.html"><i class="fa fa-check"></i><b>4</b> Labor market analysis with Twitter data</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Twitter Analytics</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="finetuning-bert-based-models" class="section level1" number="3">
<h1><span class="header-section-number">Chapter 3</span> Finetuning BERT-based models</h1>
<p>In the past few years, pretrained language models have revolutionized the field of NLP by achieving state-of-the-art results in a variety of natural language understanding tasks (Peters et al., 2018; Devlin et al., 2019). These models improve on existing word embedding methods, such as Word2Vec (Mikolov et al., 2013), by learning stable embedding representations from massive text corpora.</p>
<p>One of the models leading this revolution is the Bidirectional Encoder Representations from Transformers model (BERT, Devlin et al., 2019), which allowed for bi-directionality, through masked language modeling, and leveraged self-attention through its Transformer-based architecture (Vaswani et al., 2017). The model was pretrained on BooksCorpus (800M words) (Zhu et al., 2015) and English Wikipedia (2.5B words) using two unsupervised tasks, namely masked language modeling and next-sentence prediction. This model can later be fine-tuned on a variety of downstream tasks, including text classification, achieving high performance.</p>
<p>In this part, we show how to fine-tune a BERT-based model for tweet classification. To do so, we mostly rely on the Python package <code>simpletransformers</code>, built on top of the famous <code>transformers</code> Python package developed by Hugging Face.</p>
<div id="training-the-model" class="section level2" number="3.1">
<h2><span class="header-section-number">3.1</span> Training the model</h2>
<p>After loading the set of labelled tweets in a dataframe <code>df</code>, we perform a train-test split (70-30) on it:</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb10-1"><a href="finetuning-bert-based-models.html#cb10-1" aria-hidden="true" tabindex="-1"></a>train_df <span class="op">=</span> df.sample(frac<span class="op">=</span><span class="fl">0.7</span>,random_state<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb10-2"><a href="finetuning-bert-based-models.html#cb10-2" aria-hidden="true" tabindex="-1"></a>val_df <span class="op">=</span> df.drop(train_df.index).reset_index(drop<span class="op">=</span><span class="va">True</span>)</span></code></pre></div>
<p>We then define specific arguments for the fine-tuning such as the batch size <code>train_batch_size</code>, the number of epochs <code>num_train_epochs</code> or the output path <code>output_dir</code>. The models are evaluated at every epoch in terms of AUROC on the test set. The model with the highest AUROC on the test set is considered the best model and saved at <code>best_model_dir</code>. We also use early stopping which consists in stopping the training if the AUROC on the test set has not improved after <code>early_stopping_patience</code> epochs. A complete list of the training arguments can be found <a href="https://simpletransformers.ai/docs/usage/#configuring-a-simple-transformers-model">here</a>.</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb11-1"><a href="finetuning-bert-based-models.html#cb11-1" aria-hidden="true" tabindex="-1"></a>    classification_args <span class="op">=</span> { <span class="st">&#39;train_batch_size&#39;</span>: <span class="dv">8</span>,</span>
<span id="cb11-2"><a href="finetuning-bert-based-models.html#cb11-2" aria-hidden="true" tabindex="-1"></a>                            <span class="st">&#39;overwrite_output_dir&#39;</span>: <span class="va">True</span>,</span>
<span id="cb11-3"><a href="finetuning-bert-based-models.html#cb11-3" aria-hidden="true" tabindex="-1"></a>                            <span class="st">&#39;evaluate_during_training&#39;</span>: <span class="va">True</span>,</span>
<span id="cb11-4"><a href="finetuning-bert-based-models.html#cb11-4" aria-hidden="true" tabindex="-1"></a>                            <span class="st">&#39;save_model_every_epoch&#39;</span>: <span class="va">True</span>,</span>
<span id="cb11-5"><a href="finetuning-bert-based-models.html#cb11-5" aria-hidden="true" tabindex="-1"></a>                            <span class="st">&#39;save_eval_checkpoints&#39;</span>: <span class="va">True</span>,</span>
<span id="cb11-6"><a href="finetuning-bert-based-models.html#cb11-6" aria-hidden="true" tabindex="-1"></a>                            <span class="st">&#39;output_dir&#39;</span>: path_to_store_model,</span>
<span id="cb11-7"><a href="finetuning-bert-based-models.html#cb11-7" aria-hidden="true" tabindex="-1"></a>                            <span class="st">&#39;best_model_dir&#39;</span>: path_to_store_best_model,</span>
<span id="cb11-8"><a href="finetuning-bert-based-models.html#cb11-8" aria-hidden="true" tabindex="-1"></a>                            <span class="st">&#39;evaluate_during_training_verbose&#39;</span>: <span class="va">True</span>,</span>
<span id="cb11-9"><a href="finetuning-bert-based-models.html#cb11-9" aria-hidden="true" tabindex="-1"></a>                            <span class="st">&#39;num_train_epochs&#39;</span>: num_train_epochs,</span>
<span id="cb11-10"><a href="finetuning-bert-based-models.html#cb11-10" aria-hidden="true" tabindex="-1"></a>                            <span class="st">&quot;use_early_stopping&quot;</span>: <span class="va">True</span>,</span>
<span id="cb11-11"><a href="finetuning-bert-based-models.html#cb11-11" aria-hidden="true" tabindex="-1"></a>                            <span class="st">&quot;early_stopping_delta&quot;</span>: <span class="dv">0</span>,</span>
<span id="cb11-12"><a href="finetuning-bert-based-models.html#cb11-12" aria-hidden="true" tabindex="-1"></a>                            <span class="st">&quot;early_stopping_metric&quot;</span>: <span class="st">&quot;auroc&quot;</span>,</span>
<span id="cb11-13"><a href="finetuning-bert-based-models.html#cb11-13" aria-hidden="true" tabindex="-1"></a>                            <span class="st">&quot;early_stopping_metric_minimize&quot;</span>: <span class="va">False</span>,</span>
<span id="cb11-14"><a href="finetuning-bert-based-models.html#cb11-14" aria-hidden="true" tabindex="-1"></a>                            <span class="st">&#39;early_stopping_patience&#39;</span>: <span class="dv">3</span>}</span></code></pre></div>
<p>Once the classification arguments are defined, we can initiate the fine-tuning. In our case, for English tweet classification, we use a version of BERT that was further pretrained on English tweets by <a href="https://deeppavlov.ai">Deep Pavlov</a>, therefore enhancing the classification performance in the Twitter context. We need to define the <code>model_name</code>, which is <code>bert</code> in our case but can also be other more sophisticated architectures such as <code>roberta</code>. The <code>model_type</code> refers to the model name on the <a href="https://huggingface.co/models">Hugging Face model hub</a>. As we only cover binary classification here, the number of labels <code>num_labels</code> is set to 2.</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb12-1"><a href="finetuning-bert-based-models.html#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> simpletransformers.classification <span class="im">import</span> ClassificationModel</span>
<span id="cb12-2"><a href="finetuning-bert-based-models.html#cb12-2" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> ClassificationModel(model_name<span class="op">=</span><span class="st">&#39;bert&#39;</span>,</span>
<span id="cb12-3"><a href="finetuning-bert-based-models.html#cb12-3" aria-hidden="true" tabindex="-1"></a>                            model_type<span class="op">=</span><span class="st">&#39;DeepPavlov/bert-base-cased-conversational&#39;</span>,</span>
<span id="cb12-4"><a href="finetuning-bert-based-models.html#cb12-4" aria-hidden="true" tabindex="-1"></a>                            num_labels<span class="op">=</span><span class="dv">2</span>,</span>
<span id="cb12-5"><a href="finetuning-bert-based-models.html#cb12-5" aria-hidden="true" tabindex="-1"></a>                            use_cuda<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb12-6"><a href="finetuning-bert-based-models.html#cb12-6" aria-hidden="true" tabindex="-1"></a>                            args<span class="op">=</span>classification_args)</span></code></pre></div>
<p>Once the model has been loaded, we can launch the fine-tuning:</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb13-1"><a href="finetuning-bert-based-models.html#cb13-1" aria-hidden="true" tabindex="-1"></a>model.train_model(train_df<span class="op">=</span>train_df, eval_df<span class="op">=</span>eval_df, output_dir<span class="op">=</span>path_to_store_model)</span></code></pre></div>
<p>The training is now launched. When it is finished, we can use the best model in terms of AUROC on the test set and evaluate it on a bigger random set of tweets.</p>
</div>
<div id="evaluation-on-the-random-set" class="section level2" number="3.2">
<h2><span class="header-section-number">3.2</span> Evaluation on the random set</h2>
<p>While evaluating the model on the test set is useful to determine which classifier is best suited for the task, this performance might not be representative of the performance on a random set of tweets as the imbalance on the latter is much more extreme than on the test set. In this case, we needed to find a way to evaluate our classifiers in real-world settings. To do so, we used the best model from our training iterations to infer the confidences scores of each tweet out of a large random sample of 100 million tweets. We then ranked the tweets based on their confidence score in a descending way and sampled tweets along the confidence score distribution, overweighting the top of the distribution. In total, we sampled 200 tweets out of the 100 million random sample with ranks ranging from 1 to 1 million. The function used to do this sampling is as follows:</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb14-1"><a href="finetuning-bert-based-models.html#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_sampled_indices(n_sample<span class="op">=</span><span class="dv">10</span>, n_cutoff<span class="op">=</span><span class="dv">6</span>):</span>
<span id="cb14-2"><a href="finetuning-bert-based-models.html#cb14-2" aria-hidden="true" tabindex="-1"></a>    sampled_points <span class="op">=</span> []  <span class="co"># index of scores around which we sample n_sample tweets</span></span>
<span id="cb14-3"><a href="finetuning-bert-based-models.html#cb14-3" aria-hidden="true" tabindex="-1"></a>    sampled_ranks <span class="op">=</span> []  <span class="co"># ranks of sampled tweets</span></span>
<span id="cb14-4"><a href="finetuning-bert-based-models.html#cb14-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> point, rank <span class="kw">in</span> <span class="bu">enumerate</span>(<span class="bu">sorted</span>(<span class="bu">set</span>([<span class="bu">int</span>(x) <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(n_cutoff) <span class="cf">for</span> x <span class="kw">in</span> np.logspace(i, i <span class="op">+</span> <span class="dv">1</span>, i <span class="op">+</span> <span class="dv">1</span>)]))):</span>
<span id="cb14-5"><a href="finetuning-bert-based-models.html#cb14-5" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="kw">not</span> point:</span>
<span id="cb14-6"><a href="finetuning-bert-based-models.html#cb14-6" aria-hidden="true" tabindex="-1"></a>            new_ranks <span class="op">=</span> <span class="bu">list</span>(<span class="bu">range</span>(rank, rank <span class="op">+</span> n_sample))</span>
<span id="cb14-7"><a href="finetuning-bert-based-models.html#cb14-7" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb14-8"><a href="finetuning-bert-based-models.html#cb14-8" aria-hidden="true" tabindex="-1"></a>            new_ranks <span class="op">=</span> <span class="bu">list</span>(<span class="bu">range</span>(rank <span class="op">+</span> <span class="dv">1</span>, rank <span class="op">+</span> n_sample <span class="op">+</span> <span class="dv">1</span>))</span>
<span id="cb14-9"><a href="finetuning-bert-based-models.html#cb14-9" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">&#39;Index of sampled point:&#39;</span>, point)</span>
<span id="cb14-10"><a href="finetuning-bert-based-models.html#cb14-10" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">&#39;Sampled ranks:&#39;</span>, new_ranks)</span>
<span id="cb14-11"><a href="finetuning-bert-based-models.html#cb14-11" aria-hidden="true" tabindex="-1"></a>        sampled_points.extend([point] <span class="op">*</span> n_sample)</span>
<span id="cb14-12"><a href="finetuning-bert-based-models.html#cb14-12" aria-hidden="true" tabindex="-1"></a>        sampled_ranks.extend(new_ranks)</span>
<span id="cb14-13"><a href="finetuning-bert-based-models.html#cb14-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> sampled_points, sampled_ranks</span></code></pre></div>
<p>We then labelled these sampled tweets, which allowed us to get an estimate of the precision of the classifiers (see figure XXX).</p>
<p><strong>ADD FIGURE with ranks x-axis and percentage of positives y-axis</strong></p>
</div>
<div id="active-learning" class="section level2" number="3.3">
<h2><span class="header-section-number">3.3</span> Active learning</h2>
<p>While determining an initial list of n-grams to build a labelled set from is a good strategy to get a decent classification performance, it is unlikely to capture all the linguistic subtleties humans use on social media to talk about their labor market situation. In this case, we ideally need to label more tweets and need to determine which are the most informative to respect our labeling budget constraint.</p>
<p>When faced with a classification task in which the minority class is extremely rare, active learning allows to minimize the number of labels required for a classifier to achieve good performance. At each iteration, a trained model is used to query new samples expected to lead to high improvements in validation accuracy. These samples are, in turn, labeled by humans and then used for training in the next iteration of the model. There are two main approaches to identifying the most informative samples: uncertainty sampling  and diversity sampling , which have been coined as the ``two faces of active learning’’~. While uncertainty sampling defines the most informative samples as the ones the model is the most uncertain about (e.g. in a binary context, this boundary is at 0.5), diversity sampling consists of selecting examples to label from different homogeneous clusters of the feature space.</p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="training-data-preparation.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="labor-market-analysis-with-twitter-data-1.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/worldbank/SDG-big-data/tree/GPS-analytics/02-model_training_eval.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["twitter-analytics.pdf", "twitter-analytics.epub"],
"search": {
"engine": "lunr",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

</body>

</html>
